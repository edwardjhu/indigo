---
title: About
layout: page
---
![Profile Image]({% if site.external-image %}{{ site.picture_hd }}{% else %}{{ site.url }}/{{ site.picture_hd }}{% endif %})

<p>Edward Hu is a founding partner in a stealth AI company in Woodside, CA. He was a researcher at OpenAI and received his research training as a Ph.D. student advised by <a href="https://yoshuabengio.org/">Yoshua Bengio</a>, a recipient of the 2018 A.M. Turing Award.</p>

<p>Before graduate school, Edward was a researcher at Microsoft, where he invented <a href="https://github.com/microsoft/LoRA">LoRA</a> and <a href="https://github.com/microsoft/mup">μTransfer</a>. LoRA is now one of the most popular methods for customizing AI models, and μTransfer is underpinning the largest AI models being developed today.</p>

<h2>Selected Publications</h2>

<ul class="publications">
	Amortizing Intractable Inference in Large Language Models<br>
	<i>ICLR 2024 (oral presentation, Outstanding Paper Honorable Mention)</i><br>
	[<a href="https://arxiv.org/abs/2310.04363">Paper</a> | <a href="https://github.com/GFNOrg/gfn-lm-tuning">Code</a>]<br>
	<br>
	μTransfer: Tuning Large Neural Networks via Zero-Shot Hyperparameter Transfer<br>
	<i>NeurIPS 2021</i><br>
	[<a href="https://arxiv.org/abs/2203.03466">Paper</a> | <a href="https://www.microsoft.com/en-us/research/blog/%c2%b5transfer-a-technique-for-hyperparameter-tuning-of-enormous-neural-networks/">Blog</a> | <a href="https://github.com/microsoft/mup">Code</a> | <a href="https://www.youtube.com/watch?v=z8-C42mAwBc">Video</a> | <a href="https://www.theregister.com/2022/03/14/microsoft_openai_mutransfer/">TheRegister</a> | <a href="https://www.techradar.com/news/microsoft-openai-may-have-solved-a-fundamental-ai-bottleneck">TechRadar</a> | <a href="https://analyticsindiamag.com/interview-with-the-team-behind-microsofts-%C2%B5transfer/">AIM</a>]<br>
	<br>
	LoRA: Low-Rank Adaptation of Large Language Models<br>
	<i>ICLR 2022</i><br>
	[<a href="https://arxiv.org/abs/2106.09685">Paper</a> | <a href="https://www.youtube.com/watch?v=DhRoTONcyZE">Video</a> | <a href="https://github.com/microsoft/LoRA">Code</a> | Mentioned in <a href="https://blogs.microsoft.com/ai-for-business/ai-at-scale-technology/#:~:text=We%20also%20developed,or%20downstream%20task.">"The innovation behind AI at Scale"</a>]<br>
	<br>
	GFlowNet Foundations<br>
	<i>JMLR 2023</i><br>
	[<a href="https://arxiv.org/abs/2111.09266">Paper</a>]<br>
	<br>
	μP: Feature Learning in Infinite-Width Neural Networks<br>
	<i>ICML 2021</i><br>
	[<a href="https://arxiv.org/abs/2011.14522">Paper</a> | <a href="https://www.microsoft.com/en-us/research/blog/on-infinitely-wide-neural-networks-that-exhibit-feature-learning/">Blog</a> | <a href="https://github.com/edwardjhu/TP4">Code</a>]<br>
	<br>
	Improved Image Wasserstein Attacks and Defenses<br>
	<i>Best Paper at ICLR Trustworthy ML Workshop 2020</i><br>
	[<a href="https://arxiv.org/abs/2004.12478">Paper</a> | <a href="https://github.com/edwardjhu/improved_wasserstein">Code</a>]<br>
</ul>
<br>